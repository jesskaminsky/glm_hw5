---
title: "glm_hw5"
author: "Jess Kaminsky"
date: "4/11/2018"
output: html_document
---

```{r setup, include=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(lubridate)
library(metRology)
library(ggplot2)
library(lme4)
library(dplyr)
```

## Chapter 7 - Problem 2

```{r}
#sex is 1 if female

nsims <- 1000
elevator <- c()

for (i in 1:nsims) {
  sex <- rbinom(10, 1 , 0.52)
  log_weight <- ifelse(sex == 0, rnorm(10, 5.13, 0.17), rnorm(10, 4.96, 0.20))
  weight = exp(log_weight)
  elevator[i] = sum(weight)
}

prob <- sum(elevator > 1750) / length(elevator)
cat(paste("P(elevator breaks) is approximately ", round(prob, 3) * 100, "%"))
```



## Chapter 7 - Problem 8

### Part A

In order to simulate 1000 draws of our variables - cost difference and effectiveness difference - I drew 1000 observations from a normal distribtuion with mean 600 and standard deviation 55.47 = (400/sqrt(52)) and normal with mean 3 and standard deviation 0.99 = (1/sqrt(102)), respectively. For this stimuation I used the formula $\sigma = \frac{SE}{\sqrt{df + k}} $ Where n = df + k and k in the number of predictors in the model.

```{r}
cost_diff <- rnorm(1000, mean = 600, sd = 400/sqrt(52))
eff_diff <- rnorm(1000, mean = 3, sd = 1/sqrt(102))

plot(cost_diff, eff_diff, xlab = "Cost Difference", ylab = "Effectiveness Difference", main = "Chapter 7 - Problem 8: Part A")
```

### Part B

To generate an estimate of the ratio between cost difference and effectiveness difference, I drew 1000 samples of 1000 from the previously mentioned normal distributions then divided all observations of cost by their respective observation of effectiveness. I then found the mean and quantiles from the sample of all of these ratio esimates, which is presented below.

```{r}
cost_mat <- c()
eff_mat <- c()
for(i in 1:1000) {
  cost_mat <- rbind(cost_mat, rnorm(1000, mean = 600, sd = 400/sqrt(52)))
  eff_mat <- rbind(eff_mat, rnorm(1000, mean = 3, sd = 1/sqrt(102)))
}

ratio_mat <- cost_mat/eff_mat

cat(paste("Estimate of Cost-Effectiveness Ratio: ", round(mean(ratio_mat), 3), "\n"))
cat("50% and 95% Intervals for C-E ratio \n")
quantile(ratio_mat, c(.25, .75, .975))
```

The results of the same simulation as above are presented below - I have changed the value of standard error from 1 to 2, which has changed the standard deviation of the distribution of effectiveness from 0.099 to 0.198

```{r}
cost_diff2 <- rnorm(1000, mean = 600, sd = 400/sqrt(52))
eff_diff2 <- rnorm(1000, mean = 3, sd = 2/sqrt(102))

plot(cost_diff2, eff_diff2, xlab = "Cost Difference", ylab = "Effectiveness Difference", main = "Chapter 7 - Problem 8: Part C")

ratio2 <- cost_diff2/eff_diff2

cost_mat2 <- c()
eff_mat2 <- c()
for(i in 1:1000) {
  cost_mat2 <- rbind(cost_mat2, rnorm(1000, mean = 600, sd = 400/sqrt(52)))
  eff_mat2 <- rbind(eff_mat2, rnorm(1000, mean = 3, sd = 1/sqrt(102)))
}

ratio_mat2 <- cost_mat2/eff_mat2

mean(ratio_mat2)
quantile(ratio_mat2, c(.25, .75, .975))
```

## Chapter 8 - Problem 1

### Part A

```{r}
#generate fake data
x.1 <- 1:100
x.2 <- rbinom(n = 100, 1, 0.5)
y <- 3 + .1*x.1 + .5*x.2 + rnorm(100, 0, 1)

#run the linear model on the simulated data
model_81a <- lm(y~x.1 + x.2)

estimates <- summary(model_81a)$coefficients[,1]
stderr <- summary(model_81a)$coefficients[,2]
regression_CI <- cbind(Lower_68_CI = estimates - stderr, Upper_68_CI = estimates + stderr)


b.x0 <- 3
b.x1 <- 0.1
b.x2 <- 0.5

bse.x0 <- se.coef(model_81a)[1]
bse.x1 <- se.coef(model_81a)[2]
bse.x2 <- se.coef(model_81a)[3]

bhat.x0 <- coef(model_81a)[1]
bhat.x1<- coef(model_81a)[2]
bhat.x2 <- coef(model_81a)[3]

cover.x0 <- abs(b.x0 - bhat.x0) < bse.x0
cover.x1 <- abs(b.x1 - bhat.x1) < bse.x1
cover.x2 <- abs(b.x2 - bhat.x2) < bse.x2

coverage <- cbind(Intercept = cover.x0, x.1 =  cover.x1, x.2 = cover.x2)
dimnames(coverage)[[1]] = "CI Contains True Value"

#coverage
#regression_CI
```
 
We simulate data from the following model 

$y = 3 + 0.1x1 + 0.5x2 + \epsilon$ where $\epsilon \sim N(0,1)$

Then we fit a linear regression to these data and generate the following coefficient estimates:

```{r, echo = FALSE}
beta_est <- cbind(Intercept = bhat.x0, x.1 = bhat.x1, x.2 = bhat.x2)
dimnames(beta_est)[[1]] <- "Point Estimate"
beta_est
```

We can then use the standard error of each estimate to generate 68% confidence intervals for the point estimates of each coefficient.

```{r, echo = FALSE}
regression_CI
```
Therefore, we see the following results. The 68% confidence intervals do not always cover the true value of the coefficent for each term in the model.

```{r, echo = FALSE}
coverage
```

### Part B

After running the simulation from the previous question 1000 times, I have calculated the confidence coverage for the 68% intervals for each of the three coefficients in the model. The probabilities that the 68% confidence interval will cover the true paramater for each of the coefficents are as follows. 

```{r, echo = FALSE}
cover <- matrix(nrow = 1000, ncol = 3)

for(s in 1:1000) {
  x.1b <- 1:100 
  x.2b <- rbinom(n = 100, 1, 0.5)
  yb <- 3 + .1*x.1b + .5*x.2b + rnorm(100, 0, 1)
  model_81b <- lm(yb ~ x.1b + x.2b)
  b <- c(b.x0, b.x1, b.x2)
  hat <- coef(model_81b)
  se <- se.coef(model_81b)
  cover[s,] <- abs(b-hat) < se
}

cover_probs <- apply(cover, 2, mean)
cover_probs <- as.matrix(cover_probs)
dimnames(cover_probs)[[1]] <- c("Intercept", "x.1", "x.2")
dimnames(cover_probs)[[2]] <- "68% Confidence Coverage"
cover_probs
```

### Part C

I have performed the same simulation as the problem above; however, I fit the linear regression with errors following a t-distribution with mean = 0, scale = 5, and df = 4. The 68% confidence coverage for the coeffiencts are presented below.

```{r, echo = FALSE}
coverT <- matrix(nrow = 1000, ncol = 3)

for(s in 1:1000) {
  x.1c <- 1:100 
  x.2c <- rbinom(n = 100, 1, 0.5)
  yc <- 3 + .1*x.1c + .5*x.2c + rt.scaled(100, df = 4, mean = 0, sd = 5)
  model_81c <- lm(yb ~ x.1c + x.2c)
  b <- c(b.x0, b.x1, b.x2)
  hat <- coef(model_81c)
  se <- se.coef(model_81c)
  coverT[s,] <- abs(b-hat) < se
}

cover_probsT <- apply(coverT, 2, mean)
cover_probsT <- as.matrix(cover_probsT)
dimnames(cover_probsT)[[1]] <- c("Intercept", "x.1", "x.2")
dimnames(cover_probsT)[[2]] <- "68% Confidence Coverage"
cover_probsT

```

By accurately fitting the linear model with t errors rather than normal errors, we increase our ability to accurately capture and predict the true value of the coefficients.

## Chapter 8 - Problem 4

### Part A

We will perform predictive simulation to generate 1000 datasets based on fitting a poisson regression model predicting number of unprotected sex acts at follow up from baseline hiv status using the risky behavior data. After generating the data sets, we are interested in how well the model fits our data. We can explore this by comparing the original dataset to the datasets generated by the model. We are interested in comparing the percent of observations equal to 0 and the percent that are greater than 10 in our simulated data.

```{r, echo = FALSE}
risky <- read.csv("risky_behaviors.csv")[-1]
model_4a <- glm(round(fupacts) ~ bs_hiv, family = poisson, data = risky)

X <- cbind(rep(1, length(risky$fupacts)), risky$bs_hiv)
sim4a <- sim(model_4a, 1000)
y4a <- array(NA, c(1000, length(risky$fupacts)))
for (s in 1:1000) {
  y4a.hat <- exp(X %*% sim4a@coef[s,])
  y4a[s,] <- rpois(length(risky$fupacts), y4a.hat)
}

zero_test <- function(x) {
  mean (x==0)
}

ten_test <- function(x) {
  mean(x > 10)
}

zero.rep <- rep(NA, 1000)
for(s in 1:1000) {
  zero.rep[s] <- zero_test(y4a[s,])
}

ten.rep <- rep(NA, 1000)
for(t in 1:1000){
  ten.rep[t] <- ten_test(y4a[t,])
}

cat(paste("Simulated Percent of observations equal to zero: ", round(mean(zero.rep)*100, 3), "% \n"))

cat(paste("Actual Percent of observations equal to zero: ", round(mean(round(risky$fupacts) == 0)*100, 3), "% \n\n"))

cat(paste("Simulated Percent of observations greater than ten: ", round(mean(ten.rep)*100, 3), "% \n"))

cat(paste("Actual Percent of observations greater than ten: ", round(mean(round(risky$fupacts)  > 10)*100, 3), "% \n"))
```

### Part B

We will now perform the same simulation as above, but we will fit the data to an overdispersed poission regression model. A comparison of the original and simulated datasets is presented below.

```{r, echo = FALSE}
model_4b <- glm(round(fupacts) ~ bs_hiv, family = quasipoisson, data = risky)

Xb <- cbind(rep(1, length(risky$fupacts)), risky$bs_hiv)
sim4b <- sim(model_4b, 1000)
y4b <- array(NA, c(1000, length(risky$fupacts)))
for (s in 1:1000) {
  y4b.hat <- exp(Xb %*% sim4b@coef[s,])
  y4b[s,] <- rpois(length(risky$fupacts), y4b.hat)
}


zero.rep <- rep(NA, 1000)
for(s in 1:1000) {
  zero.rep[s] <- zero_test(y4b[s,])
}


ten.rep <- rep(NA, 1000)
for(t in 1:1000){
  ten.rep[t] <- ten_test(y4b[t,])
}

cat(paste("Simulated Percent of observations equal to zero: ", round(mean(zero.rep)*100, 3), "% \n"))

cat(paste("Actual Percent of observations equal to zero: ", round(mean(round(risky$fupacts) == 0)*100, 3), "% \n\n"))

cat(paste("Simulated Percent of observations greater than ten: ", round(mean(ten.rep)*100, 3), "% \n"))

cat(paste("Actual Percent of observations greater than ten: ", round(mean(round(risky$fupacts)  > 10)*100, 3), "% \n"))
```

The simulated and actual percentages are closer than in the previous question. This indicated that the overdispersed poisson model is more appropriate for our dataset than the poisson model.

### Part C

Again, we will perfom the same simulation as above - using an overdispersed poisson model - but we will add in the covariate for baseline number of unprotected sex acts. A summary of the generated data is presented below.

```{r, echo = FALSE}
model_4c <- glm(round(fupacts) ~ bs_hiv + bupacts, family = quasipoisson, data = risky)

Xc <- cbind(rep(1, length(risky$fupacts)), risky$bs_hiv, risky$bupacts)
sim4c <- sim(model_4c, 1000)
y4c <- array(NA, c(1000, length(risky$fupacts)))
for (s in 1:1000) {
  y4c.hat <- exp(Xc %*% sim4c@coef[s,])
  y4c[s,] <- rpois(length(risky$fupacts), y4c.hat)
}


zero.rep <- rep(NA, 1000)
for(s in 1:1000) {
  zero.rep[s] <- zero_test(y4c[s,])
}


ten.rep <- rep(NA, 1000)
for(t in 1:1000){
  ten.rep[t] <- ten_test(y4c[t,])
}

cat(paste("Simulated Percent of observations equal to zero: ", round(mean(zero.rep)*100, 3), "% \n"))

cat(paste("Actual Percent of observations equal to zero: ", round(mean(round(risky$fupacts) == 0)*100, 3), "% \n\n"))

cat(paste("Simulated Percent of observations greater than ten: ", round(mean(ten.rep)*100, 3), "% \n"))

cat(paste("Actual Percent of observations greater than ten: ", round(mean(round(risky$fupacts)  > 10)*100, 3), "% \n"))

```

Our accuracy in generating observations equal to 0 has not improved. We are successful in generating approximately the appropriate number of obervations greater than ten.

## Chapter 11 - Problem 4

The analyses in the remaining questions of this assignment use the cd4 data. For all of these analyses and visualizations, I will use a smaller cd4 data set that only includes observations without any NA values. 

### Part A

The graph below shows each child's cd4 percentage, on the square root scale, over time.

```{r}
cd4 <- read.csv("cd4.csv")

cd4$vdate <- mdy(cd4$vdate)
cd4_full <- cd4[complete.cases(cd4),]

ggplot(data=cd4_full, aes(x=vdate, y=sqrt(cd4pct), group=newpid, colour=factor(newpid)))+ 
    geom_line(size=.75) + geom_point() + theme(legend.position="none") + xlab("Year") + ylab("Square Root of CD4 Percentage") + ggtitle("Chapter 11 - Problem 4", subtitle = "Part A")
    
```

### Part B 

The graph below shows the linear fit for each child predicting the square root of their cd4 percentage from time.

```{r}
attach(cd4_full)

plot(cd4_full$vdate[newpid == 1], sqrt(cd4_full$cd4pct[newpid ==1]), xlim = c(as.Date("1988-03-07"), as.Date("1991-01-14")), ylim = c(0, 10), xlab = "Year", ylab = "Square Root of CD4 Percentage", main = "Chapter 11 - Problem 4 \n Part B")


for(i in unique(cd4_full$newpid)) {
  temp_mod <- lm(sqrt(cd4pct) ~ vdate, data = cd4_full[newpid == i,])
  cd4_full$intercept[newpid == i] <- temp_mod$coefficients[1]
  cd4_full$slope[newpid == i] <- temp_mod$coefficients[2]
  coeffs <- coef(temp_mod)
   if(is.na(coeffs[2])) {
     coeffs[2] <- 0
   }
  abline(coeffs) 
  }
```
### Part C 

First, I have modeled a linear fit - the slope and intercept - for each child separately. Those linear models are plotted above. Next, I will model the slopes and intercepts separately of each child as a function of treatment and age at baseline to fit between-child models. The resulting models are as follows:

$Slope = -7.0087x10^{-4} - 1.6635x10^{-4}treatment - 5.8589x10^{-5}*baseage$
$Intercept = 9.588 + 0.806*treatment + 0.207*baseage$


```{r, echo = False}
cd4_unique <- cd4_full %>% group_by(newpid) %>% slice(1)
slope_mod <- lm(slope ~ treatmnt + baseage, data = cd4_unique)
intercept_mod <- lm(intercept ~ treatmnt + baseage, data = cd4_unique)

#coefficients(intercept_mod)
#coefficients(intercept_mod)
```




## Chapter 12 - Problem 2

### Part A

We generated the following multilevel model predicting cd4 percentage from time with an intercept varying among patients

$cd4\%=71.91 - 0.01*vdate$

The coefficient for time generated by =this multilevel model with varying intercepts across children is -0.01. This means that for each child CD4 percentage decreases by 0.01 percent for every unit increase in time. A brief summary of the model is presented below.

```{r, echo = FALSE}
attach(cd4_full)
model_122a <- lmer(cd4pct ~ vdate + (1|newpid), data = cd4_full)
display(model_122a)
```

### Part B 

After extending the previous model to include child-level predictors for treatment and age at baseline, the resulting model is presented below. The intercept term of this model varies by patient.

$cd4\%= 71.57 -0.01*vdate + 1.91*treatment - 0.96*baseage $

We can interpret the coefficients as follows:
- For every unit increase in visit date, we expect cd4 percentage to decrease by 0.01%
- Being in treatment group 2, increases your expected cd4 percentage by 1.91%
- For every 1 year increase in age at baseline, we expect cd4 percentage to decrease by 0.96%

A brief summary of the model from R is shown below.

```{r,  echo = FALSE}
model_122b <- lmer(cd4pct ~ vdate + treatmnt + baseage + (1|newpid), data = cd4_full)

display(model_122b)
```

### Part C

We see a larger range of random effects from the first simple model. The random effects from the second model have less variablilty and are therefore the model is more accurate in predicting cd4 percentage. To investigate the change in models numerically we will calculate the between-child variances in the first and second model. For each model, these variances can be calculated by dividing the standard deviation of the error term for the intercept by the sum of the standard deviation of the error terms for the intercept and residual.

```{r,  echo= = FALSE}
plot(ranef(model_122a)[[1]][,1], ranef(model_122b)[[1]][,1], xlab = "Random Effects of First Model", ylab = "Random Effects of Second Model", main = "Chapter 12 - Problem 2: Part C")
```

From the first model the between-child variance is $\frac{11.77}{11.77+7.12} = 0.623 = 62.3%$

```{r,  echo= = FALSE}
display(model_122a)
```

From the second model, $\frac{11.57}{11.57+7.12} = 0.619 = 61.9%$

```{r,  echo= = FALSE}
display(model_122b)
```

The between child variance reduced minimally, this aligns with the small reduction in the standard error of the intercepts from the first to second model.

### Part D 

We will use ANOVA to compare the two models generated in this exercise. The p-value is significant at the $\alpha = 0.05$ level indicating that these two models are significantly different. The addition of treatment and age at baseline are significant in predicting cd4 percentage.

```{r, echo = FALSE}
anova(model_122b, model_122a)
```

## Chapter 12 - Problem 3

### Part A

In order to create a hypothetical next timepoint for each patient I found the average time difference between their visits and added that difference to their last visit. If a patient only had one visit and therefore no difference between visit dates, I used the average of the average differences. Then, I used the model from above predicting cd4 prercentage, vist date, treatment group, and baseline age to predict cd4 percentage for each patient and their new hypothetical next timepoint. The predicted values for each patient are listed below.

```{r, echo = FALSE}
cd4_averages <- cd4_full %>% group_by(newpid) %>% arrange(vdate) %>% summarize(ave = as.numeric(mean(diff(vdate))))
  

cd4_newtime <- cd4_full %>% group_by(newpid) %>% filter(vdate == max(vdate))

for(i in 1:length(cd4_averages$ave)) {
  if(is.na(cd4_averages$ave[i])) {
    cd4_averages$ave[i] <- mean(cd4_averages$ave, na.rm = TRUE)
  }
} 

cd4_newtime$vdate <- cd4_newtime$vdate + cd4_averages$ave

newtime_predict <- predict(model_122b, cd4_newtime)
cat(paste("id ","visit date ", "predicted value\n", " "))
cat(paste(cd4_newtime$newpid, cd4_newtime$vdate, newtime_predict, "\n"))
```
### Part B

While continuing to use the same predictive model, I will use the same dataset as the previous question but change each patients baseline age to 4 and generate new predictions for cd4 percentage.

```{r, echo = FALSE}
cd4_newtime4 <- cd4_newtime
cd4_newtime4$baseage <- 4

newtime_predict4 <- predict(model_122b, cd4_newtime4)

cat(paste("id ","visit date ", "predicted value\n", " "))
cat(paste(cd4_newtime4$newpid, cd4_newtime4$vdate, newtime_predict4, "\n"))

```

## Chapter 12 - Problem 4

We will now generate more predictions - this time using the original, na omitted data except every patients visit date is replaced by the latest date represented in the dataset which is January 14, 1991. We can see the distribution of predicted CD4 percentage after 1000 simulations in the histogram below. The observed CD4 percentages at the final date in the dataset fall in the middle of the distribution which gives us confidence that we have a good model.

```{r, echo = FALSE}
final_time <- cd4_full
final_time$vdate <- max(final_time$vdate)

final_time <- final_time %>% group_by(newpid) %>% slice(1)

final_predict <- predict(model_122b, final_time)
hist(rnorm(1000, mean(final_predict), sd(final_predict)))
cat(paste("\nMean CD4 percentage from Simulated Data using Final date", round(mean(final_predict),3), "\n"))
cat(paste("Standard Deviation CD4 percentage from Simulated Data using Final date", round(sd(final_predict),3), "\n\n"))


cat(paste("Observed CD4 Percentages on Max Date: ", cd4_full$cd4pct[vdate == max(vdate)][1], " and ", cd4_full$cd4pct[vdate == max(vdate)][2], "\n"))

cat(paste("Average CD4 Percentage on Max Date: ", mean(cd4_full$cd4pct[vdate == max(vdate)]), "\n"))
```



